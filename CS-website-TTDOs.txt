CS website DEVELOPMENTS

TTDOs (Feb 2018)



OTHER IMPROVEMENTS to implement in the future (descending order of priority/value):
-add .CSV, .JSON, and .R file links above searchable replication table;
-update badge order: open materials, prereg, then data (given open materials *MOST* fundamental; and given data should be last for when we'll have reproducbility/Code Ocean icon)
-rep.type.effort full description ON HOVER (insert "title" attribute inside <td> tag issue resolved; question is about added value of this extra info RELATIVE to how much it slows down loading of table! [though perhaps use some kind of CSS text sprite?? doesn't look promising after quick search])
-add ES.description values for other more common ESs??? (incl. adding units of measurement, e.g., facial feedback hypothesis 0-9 scale)

-remove weird ES acronyms (e.g., "MD", "PD", "IRD") for unstandardized ESs; simply display ES+/-error interval (e.g., MD = -.65 ± .45 would become -.65 ± .45 or Δ delta symbol?) [this also will fix sorting issue for all unstandardized ESs!]

-row background JS where alternate based on "factored" target.effect instead of alternating rows;
-effect.description ON HOVER (on hold because DataTables ellipsis functions overide <td> titles)

[-4. (eventually scrape and add all badge-earning Psych Science studies??; via generate-HTML-future-directions-table.R; but first work on cross-ref meta-data extraction script???)]

KNOWN ISSUES:
-unable to sort by original study year (Corker suggestion; though CAN NOW sort by original study PUBLICATION YEAR in public gSheet [Dec 7, 2017])
-sort by original/replication ES issue involving negative values (substantially improved [Dec 7, 2017]; and again this can now be done in public gSheet given values are now all disaggregated!)
-special character problems (only some characters) for hover titles (e.g., Correll active.sample.evidence ) (given problem does NOT occur for <TH> column header titles, suspect it may be a problem in the DataTables JS functions???)
-pagination issue (when click on page 2, doesn't automatically scroll to top of the table [first row])


COMING SOON:
-Bayesian replication outcome categories coming soon (emailed E-J and he's interested, but need to find project/paper lead by contacting Etz and Gronau )
-other data visualization enhancements (violin plots/overlapping histograms popups on HOVER for simple ESs; e.g., https://stackoverflow.com/questions/3541713/how-to-plot-two-histograms-together-in-r)

-wire frame drafts for crowdsourcing HTML table and other MVP features (or perhaps my "prototypes" are sufficient?)
-contact Ed Guiness guy regarding finding another volunteer programmer (hearing back from big grants in February 2018, but it'd be good to start sooner???)
-contact Lakens re: shiny app license, and possibility of hosting CurateScience.org in the future (for crowdsourcing and ability to generate EC forest plots on the fly)???? 


OTHER NOTES:
Mission statement:
CS's mission is to increase the cumulative and self-correcting nature of empirical research to accelerate the development of scientific knowledge (and applied innovations). We are achieving this by curating the (1) transparency (open materials, pre-registration, open data), (2) reproducibility, and (3) replicability of published empirical research.


**NOTES re: 2-pager for upcoming email to Funders:
-re-add "Funders can use platform/system to ensure all grantees comply with new standards of transparency and analytic reproducibility" under "future benefit"? (no will just mention this VERBALLY; remember also that i should mention VERBALLY that we plan to use OSF's API to help users link materials, data, and pre-reg info to studies [even though this is unlikely true])



indeed MetaLab is an impressive initiative; CS is unique, however, in several ways: (1) its unified framework to quantify trustworthiness (transparency, reproducibility, and replicability), (2) replication taxonomy to gauge methodological similarity (3) epistemological approaches for more nuanced evaluations and statistical interpretations of replication studies (including *ONLY* meta-analyzing replications *within* distinct operationalizations!), and more

-but for Funders can mention that we can benefit/reuse some of their contributions (e.g., ES calculation functions, meta-analytic functions, etc.) (given MetaLab funded by BITSS and LJAF, so we'll ask how we go beyond them)

