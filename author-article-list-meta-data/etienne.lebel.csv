authors,pub.year,article.title,journal.name,DOI,article.PDF.URL,PDF.views,PDF.downloads,PDF.citations,article.HTML.URL,HTML.views,article.preprint.URL,preprint.views,preprint.downloads,metrics.date,prereg.type,prereg.URL,open.mat.URL,open.data.URL,open.code.URL,rs.type,disclosure.date,article.type,rep.num,original.study,target.effects,commentaries.URLs,abstract.text,keywords,author.contributions,competing.interests,funding.sources,peer.review.editor,peer.reviewers,peer.reviews.URL
"EP LeBel, W Vanpaemel, I Cheung, & L Campbell",in press,A brief guide to evaluate replications,Meta-Psychology,,,,,,,,https://osf.io/paxyn/,,211,"January 17, 2019",,,,,,,,conceptual,,,,,"The importance of replication is becoming increasingly appreciated, however, considerably less consensus exists about how to evaluate the design and results of replications. We make concrete recommendations on how to evaluate replications with more nuance than what is typically done currently in the literature. We highlight six study characteristics that are crucial for evaluating replications: replication method similarity, replication differences, investigator independence, method/data transparency, analytic result reproducibility, and auxiliary hypotheses’ plausibility evidence. We also recommend a more nuanced approach to statistically interpret replication results at the individual-study and meta-analytic levels, and propose clearer language to communicate replication results.",transparency;  reproducibility;  direct replication;  replicability;  evaluating replications,,None to declare.,"European Commission (Marie-Curie grant, Project ID: 793669: EP LeBel, W Vanpaemel)",R Carlsson,MB Nuijten; U Schimmack,https://osf.io/dsn72/
"EP LeBel, R McCarthy, B Earp, M Elson, & W Vanpaemel",2018,A unified framework to quantify the credibility of scientific findings,Advances in Methods and Practices in Psychological Science,10.1177/2515245918787489,"https://etiennelebel.com/documents/lebeletal(2018,ampss)a-unified-framework-to-quantify-the-credibility-of-scientific-findings.pdf",,1033,20,,,https://psyarxiv.com/uwmr8,,1486,"December 15, 2018",,,,,,,,conceptual,,,,,"Societies invest in scientific studies to better understand the world and attempt to harness such improved understanding to address pressing societal problems. Published research, however, can be useful for theory or application only if it is credible. In science, a credible finding is one that has repeatedly survived risky falsification attempts. However, state-of-the-art meta-analytic approaches cannot determine the credibility of an effect because they do not account for the extent to which each included study has survived such attempted falsification. To overcome this problem, we outline a unified framework for estimating the credibility of published research by examining four fundamental falsifiability-related dimensions: (a) transparency of the methods and data, (b) reproducibility of the results when the same data-processing and analytic decisions are reapplied, (c) robustness of the results to different data-processing and analytic decisions, and (d) replicability of the effect. This framework includes a standardized workflow in which the degree to which a finding has survived scrutiny is quantified along these four facets of credibility. The framework is demonstrated by applying it to published replications in the psychology literature. Finally, we outline a Web implementation of the framework and conclude by encouraging the community of researchers to contribute to the development and crowdsourcing of this platform.",research credibility; transparency; open science; analytic reproducibility; analytic robustness; replicability,"E. P. LeBel conceived the general idea, drafted and revised the manuscript, created the figures, and executed the analytic-reproducibility checks and meta-analyses for the application of the framework to the infidelity-distress effect. W. Vanpaemel provided substantial contributions to the conceptual development of the ideas presented. W. Vanpaemel, R. J. McCarthy, B. D. Earp, and M. Elson provided critical commentary and made substantial contributions to writing and revising the manuscript. All authors approved the final submitted version of the manuscript.",None to declare.,Ministry of Culture and Science (Germany: M Elson),S Vazire,"Anonymous reviewer 1, Anonymous reviewer 2",
"EP LeBel, D Berger, L Campbell, & TJ Loving",2017,Falsifiability is not optional,Journal of Personality and Social Psychology,10.1037/pspi0000106,"https://etiennelebel.com/documents/lbcl(2017,jpsp).pdf",,,23,,,https://psyarxiv.com/dv94b/,,1407,"December 17, 2018",,,,,https://osf.io/wp6an/,,,conceptual,,,,,"Finkel, Eastwick, and Reis (2016; FER2016) argued the post-2011 methodological reform movement has focused narrowly on replicability, neglecting other essential goals of research. We agree multiple scientific goals are essential, but argue, however, a more fine-grained language, conceptualization, and approach to replication is needed to accomplish these goals. Replication is the general empirical mechanism for testing and falsifying theory. Sufficiently methodologically similar replications, also known as direct replications, test the basic existence of phenomena and ensure cumulative progress is possible a priori. In contrast, increasingly methodologically dissimilar replications, also known as conceptual replications, test the relevance of auxiliary hypotheses (e.g., manipulation and measurement issues, contextual factors) required to productively investigate validity and generalizability. Without prioritizing replicability, a field is not empirically falsifiable. We also disagree with FER2016’s position that “bigger samples are generally better, but... that very large samples could have the downside of commandeering resources that would have been better invested in other studies” (abstract). We identify problematic assumptions involved in FER2016’s modifications of our original research-economic model, and present an improved model that quantifies when (and whether) it is reasonable to worry that increasing statistical power will engender potential trade-offs. Sufficiently powering studies (i.e., 80%) maximizes both research efficiency and confidence in the literature (research quality). Given that we are in agreement with FER2016 on all key open science points, we are eager to start seeing the accelerated rate of cumulative knowledge development of social psychological phenomena such a sufficiently transparent, powered, and falsifiable approach will generate.",direct replication; falsification; power; replicability; transparency,,None to declare.,None to declare.,K Kawakami,"R Giner-Sorolla, Anonymous reviewer 2, Anonymous reviewer 3, Anonymous reviewer 4",
"EP LeBel, L Campbell, & TJ Loving",2017,Benefits of open and high-powered research outweigh costs,Journal of Personality and Social Psychology,10.1037/pspi0000049,"https://etiennelebel.com/documents/lcl(2017,jpsp).pdf",,,15,,,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2616384,3557,496,"December 17, 2018",,,,,https://osf.io/hpwqd/,,,conceptual,,,,,"Several researchers recently outlined unacknowledged costs of open science practices, arguing these costs may outweigh benefits and stifle discovery of novel findings. We scrutinize these researchers’ (a) statistical concern that heightened stringency with respect to false-positives will increase false-negatives and (b) metascientific concern that larger samples and executing direct replications engender opportunity costs that will decrease the rate of making novel discoveries. We argue their statistical concern is unwarranted given open science proponents recommend such practices to reduce the inflated Type I error rate from .35 down to .05 and simultaneously call for high-powered research to reduce the inflated Type II error rate. Regarding their metaconcern, we demonstrate that incurring some costs is required to increase the rate (and frequency) of making true discoveries because distinguishing true from false hypotheses requires a low Type I error rate, high statistical power, and independent direct replications. We also examine pragmatic concerns raised regarding adopting open science practices for relationship science (preregistration, open materials, open data, direct replications, sample size); while acknowledging these concerns, we argue they are overstated given available solutions. We conclude benefits of open science practices outweigh costs for both individual researchers and the collective field in the long run, but that short term costs may exist for researchers because of the currently dysfunctional academic incentive structure. Our analysis implies our field’s incentive structure needs to change whereby better alignment exists between researcher’s career interests and the field’s cumulative progress. We delineate recent proposals aimed at such incentive structure realignment.",open science practices; independent replication; cumulative knowledge; analytic and design flexibility,,None to declare.,None to declare.,RC Fraley,"Anonymous reviewer 1, M Kraus",
"M Heino, EI Fried, & EP LeBel",2017,Complex phenomena require sophisticated designs: Why we shouldn't give up on replicability,Frontiers in Psychology,10.3389/fpsyg.2017.01004,"https://etiennelebel.com/documents/hf&l(2017,fip).pdf",,,3,http://journal.frontiersin.org/article/10.3389/fpsyg.2017.01004/full,4862,https://osf.io/6b95w/,,268,"December 14, 2018",,,,,,,,commentary,,,,,,replicability crisis; replication; complexity; complex systems; falsification,"All authors listed, have made substantial, direct and intellectual contribution to the work, and approved it for publication.",None to declare.,"Academy of Finland (grant # 295765: M Heino), European Research Council (Consolidator grant # 647209: EI Fried)",MS Hagger,D Trafimow,
"I Cheung, L Campbell, EP LeBel, ... , & JC Yong",2016,"Registered Replication Report: Study 1 from Finkel, Rusbult, Kumashiro, & Hannon (2002) (RRR5)",Perspectives on Psychological Science,10.1177/1745691616664694,http://journals.sagepub.com/doi/pdf/10.1177/1745691616664694,,1033,24,http://journals.sagepub.com/doi/10.1177/1745691616664694,,,,,"December 15, 2018",preregplusrr,https://osf.io/2h6tf/,https://osf.io/knfy4/files/,https://osf.io/3nz7j/files/,https://osf.io/3nz7j/files/,basic4.at.subm,,replication,16,Finkel et al. (2002) Study 1,commitment on forgiveness effect,https://static1.squarespace.com/static/56c0eeaa7c65e465b5050feb/t/5804396dbe6594564b28c24b/1476671855511/2016_Finkel_PPS.pdf,"Finkel, Rusbult, Kumashiro, and Hannon (2002, Study 1) demonstrated a causal link between subjective commitment to a relationship and how people responded to hypothetical betrayals of that relationship. Participants primed to think about their commitment to their partner (high commitment) reacted to the betrayals with reduced exit and neglect responses relative to those primed to think about their independence from their partner (low commitment). The priming manipulation did not affect constructive voice and loyalty responses. Although other studies have demonstrated a correlation between subjective commitment and responses to betrayal, this study provides the only experimental evidence that inducing changes to subjective commitment can causally affect forgiveness responses. This Registered Replication Report (RRR) meta-analytically combines the results of 16 new direct replications of the original study, all of which followed a standardized, vetted, and preregistered protocol. The results showed little effect of the priming manipulation on the forgiveness outcome measures, but it also did not observe an effect of priming on subjective commitment, so the manipulation did not work as it had in the original study. We discuss possible explanations for the discrepancy between the findings from this RRR and the original study. ",commitment; rejection; relationships; analytic reproducibility; replication; preregistration,,None to declare.,None to declare.,DJ Simons,,
EP LeBel,2015,A new replication norm for psychology,Collabra: Psychology,10.1525/collabra.23,"https://etiennelebel.com/documents/l(2015,collabra).pdf",,346,10,http://collabra.org/articles/10.1525/collabra.23/,2051,,,,"December 14, 2018",,,,,,,,conceptual,,,,,"In recent years, there has been a growing concern regarding the replicability of findings in psychology, including a mounting number of prominent findings that have failed to replicate via high-powered independent replication attempts. In the face of this replicability “crisis of confidence”, several initiatives have been implemented to increase the reliability of empirical findings. In the current article, I propose a new replication norm that aims to further boost the dependability of findings in psychology. Paralleling the extant social norm that researchers should peer review about three times as many articles that they themselves publish per year, the new replication norm states that researchers should aim to independently replicate important findings in their own research areas in proportion to the number of original studies they themselves publish per year (e.g., a 4:1 original-to-replication studies ratio). I argue this simple approach could significantly advance our science by increasing the reliability and cumulative nature of our empirical knowledge base, accelerating our theoretical understanding of psychological phenomena, instilling a focus on quality rather than quantity, and by facilitating our transformation toward a research culture where executing and reporting independent direct replications is viewed as an ordinary part of the research process. To help promote the new norm, I delineate (1) how each of the major constituencies of the research process (i.e., funders, journals, professional societies, departments, and individual researchers) can incentivize replications and promote the new norm and (2) any obstacles each constituency faces in supporting the new norm.",independent replication; cumulative knowledge; replication norm,,None to declare.,None to declare.,S Vazire,"K Corker, Anonymous reviewer 2",http://s3-eu-west-1.amazonaws.com/ubiquity-partner-network/ucp/journal/collabra/collabra-pr-23-v2.pdf
"AA Aarts, ... , EP LeBel, ... , BA Nosek",2015,Estimating the [replicability] of psychological science (RPP),Science,10.1126/science.aac4716,"https://etiennelebel.com/documents/osc(2015,science).pdf",65411,,2676,,,https://osf.io/447b3/,,12390,"December 14, 2018",,,https://osf.io/ezcuj/wiki/Replicated%20Studies/,https://osf.io/ytpuq/wiki/home/,https://osf.io/ytpuq/wiki/home/,,,replication,100,,100 social/cognitive psychology effects,http://science.sciencemag.org/content/351/6277/1037.2,"[Replicability] is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams. ",,,None to declare.,None to declare.,Anonymous,Anonymous reviewer 1; Anonymous reviewer 2; Anonymous reviewer 3; Anonymous reviewer 4,
C Madurski & EP LeBel,2015,Replication difficulties of Correll's (2008) modulation of 1/f noise in a racial bias task,Psychonomic Bulletin & Review,10.3758/s13423-014-0757-4,"http://etiennelebel.com/documents/m&l(2015,pbr).pdf",,,5,,,http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2435572,1004,73,"December 20, 2018",preregplus,https://osf.io/iwe3v/,https://osf.io/iraqy/files/,https://osf.io/iraqy/files/,https://osf.io/iraqy/files/,basic4.at.subm,,replication,2,Correll (2008) Study 2,modulation of 1/f noise racial bias emission,,"Correll (2008; Study 2, Journal of Personality and Social Psychology, 94, 48–59) found that instructions to use or avoid race information decreased the emission of 1/f noise in a weapon identification task (WIT). These results suggested that 1/f noise in racial bias tasks reflected an effortful deliberative process, providing new insights regarding the mechanisms underlying implicit racial biases. Given the potential theoretical and applied importance of understanding the psychological processes underlying implicit racial biases – and in light of the growing demand for independent direct replications of findings to ensure the cumulative nature of our science – we attempted to replicate Correll’s finding in two high-powered studies. Despite considerable effort to closely duplicate all procedural and methodological details of the original study (i.e., same cover story, experimental manipulation, implicit measure task, original stimuli, task instructions, sampling frame, population, and statistical analyses), both replication attempts were unsuccessful in replicating the original finding challenging the theoretical account that 1/f noise in racial bias tasks reflects a deliberative process. However, the emission of 1/f noise did consistently emerge across samples in each of our conditions. Hence, future research is needed to clarify the psychological significance of 1/f noise in racial bias tasks.",1/f noise; implicit racial bias;  weapon identification task;  independent direct replication,,None to declare.,"Social Science and Humanities Research Council (SSHRC grant # 756-2011-0090, Canada: EP LeBel)",SD Goldinger,Anonymous reviewer 1; Anonymous reviewer 2,
"L Campbell, TJ Loving, & EP LeBel",2014,Enhancing transparency of the research process to increase accuracy of findings: A guide for relationship researchers,Personal Relationships,10.1111/pere.12053,"https://etiennelebel.com/documents/cl&l(2014,pr).pdf",,,21,,,http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2435185,1006,133,"December 20, 2018",,,,,,,,conceptual,,,,,"The purpose of this paper is to extend to the field of relationship science, recent discussions and suggested changes in open research practises. We demonstrate different ways that greater transparency of the research process in our field will accelerate scientific progress by increasing accuracy of reported research findings. Importantly, we make concrete recommendations for how relationship researchers can transition to greater disclosure of research practices in a manner that is sensitive to the unique design features of methodologies employed by relationship scientists. We discuss how to implement these recommendations for four different research designs regularly used in relationship research and practical limitations regarding implementing our recommendations and provide potential solutions to these problems.",,,None to declare.,None to declare.,J Fitness,"Anonymous reviewer 1, Anonymous reviewer 2",
EP LeBel & CJ Wilbur,2014,Big secrets do not necessarily cause hills to appear steeper,Psychonomic Bulletin & Review,10.3758/s13423-013-0549-2,"http://etiennelebel.com/documents/l&w(2014,pbr).pdf",,,19,,,,,,"December 20, 2018",preregplus,https://osf.io/dz2fx/,https://osf.io/w6kv5/files/,https://osf.io/w6kv5/files/,https://osf.io/w6kv5/files/,basic4.at.subm,,replication,2,Slepian et al. (2012) Study 1,physical burdensomeness of secrets effect,,"Slepian, Masicampo, Toosi, and Ambady (2012, Study 1, Journal of Experimental Psychology: General, 141, 619–624) found that individuals recalling and writing about a big, meaningful secret judged a pictured hill as steeper than did those who recalled and wrote about a small, inconsequential secret (with estimates unrelated to physical effort unaffected). From an embodied cognition perspective, this result was interpreted as suggesting that important secrets weigh people down. Answering to mounting calls for the crucial need of independent direct replications of published findings to ensure the self-correcting nature of our science, we sought to corroborate Slepian et al.’s finding in two extremely highpowered, preregistered studies that were very faithful to all procedural and methodological details of the original study (i.e., same cover story, study title, manipulation, measures, item order, scale anchors, task instructions, sampling frame, population, and statistical analyses). In both samples, we were unsuccessful in replicating the target finding. Although Slepian et al. reported three other studies supporting the secret burdensomeness phenomenon, we advise that these three other findings need to be independently corroborated before the general phenomenon informs theory or health interventions.",embodied cognition; secrecy; concealment of secrets; independent direct replication,,None to declare.,"Social Science and Humanities Research Council (SSHRC grant # 756-2011-0090, Canada: EP LeBel)",C Moore,A Glenberg; Anonymous reviewer 2; Anonymous reviewer 3,
EP LeBel & L Campbell,2013,Heightened sensitivity to temperature cues in individuals with high anxious attachment: Real or elusive phenomenon?,Psychological Science,10.1177/0956797613486983,"http://etiennelebel.com/documents/l&c(2013,psci).pdf",,,46,,,,,,"December 20, 2018",preregplus,https://osf.io/kizyn/,https://osf.io/qsnvb/,https://osf.io/qsnvb/,https://osf.io/qsnvb/,basic4.retro,"November 1, 2013",replication,2,Vess (2012) Study 1,anxious attachment warm food effect,,,,,None to declare.,"Social Science and Humanities Research Council (SSHRC grant # 756-2011-0090, Canada: EP LeBel); SSHRC grant (Canada: L Campbell)",E Eich,Anonymous reviewer 1,
"EP LeBel, D Borsboom, R Giner-Sorolla, F Hasselman, ... , & CT Smith",2013,PsychDisclosure.org: Grassroots support for reforming reporting standards in psychology,Perspectives on Psychological Science,10.1177/1745691613491437,"https://etiennelebel.com/documents/lbghprs(2013,pps).pdf",,,77,,,,,,"December 20, 2018",,,,,,,,conceptual,,,,,"There is currently an unprecedented level of doubt regarding the reliability of research findings in psychology. Many recommendations have been made to improve the current situation. In this article, we report results from PsychDisclosure.org, a novel open-science initiative that provides a platform for authors of recently published articles to disclose four methodological design specification details that are not required to be disclosed under current reporting standards but that are critical for accurate interpretation and evaluation of reported findings. Grassroots sentiment -- as manifested in the positive and appreciative response to our initiative -- indicates that psychologists want to see changes made at the systemic level regarding disclosure of such methodological details. Almost 50% of contacted researchers disclosed the requested design specifications for the four methodological categories (excluded subjects, nonreported conditions and measures, and sample size determination). Disclosed information provided by participating authors also revealed several instances of questionable editorial practices, which need to be thoroughly examined and redressed. On the basis of these results, we argue that the time is now for mandatory methods disclosure statements for all psychology journals, which would be an important step forward in improving the reliability of findings in psychology.",reporting standards; disclosure; methodological design specifications; methodology,,None to declare.,"Social Science and Humanities Research Council (SSHRC grant # 756-2011-0090, Canada: EP LeBel)",B Spellman,Anonymous reviewer 1,
EP LeBel & L Campbell ,2013,The interactive role of implicit and explicit partner evaluations on ongoing affective and behavioral romantic realities,Social Psychological and Personality Science,10.1177/1948550612448196,"https://etiennelebel.com/documents/l&c(2013,spps).pdf",,,10,,,,,,"December 20, 2018",,,,,,basic7,"February 15, 2018",original,,,,,"Past research on close relationships has increasingly focused on the assessment of implicit constructs to shed new light on relationship processes. However, virtually nothing is known about the role of such constructs in understanding ongoing affective and behavioral romantic realities and how implicit and explicit relationship constructs interact in the context of daily relationship outcomes. Using a 21-day diary approach, the present research examined the unique and interactive role of implicit partner evaluations and explicit partner perceptions on relationship outcomes (daily relationship quality and positive relationship behaviors enacted toward partner). Results showed that more positive implicit partner evaluations uniquely predicted more positive relationship outcomes during the 21-day diary period, but that this was especially pronounced in individuals who did not explicitly perceive their partner’s attributes in an overly positive manner. Implications for the close relationship literature are discussed.",implicit partner evaluations; explicit partner perceptions; relationship satisfaction,,None to declare.,"Social Science and Humanities Research Council (SSHRC grant # 756-2011-0090, Canada: EP LeBel), SSHRC grant (Canada: L Campbell)",C Finkenauer,Anonymous reviewer 1,
"AA Aarts, ... , EP LeBel, ... , & BA Nosek (2012)",2012,"An open, large-scale, collaborative effort to estimate the [replicability] of psychological science",Perspectives on Psychological Science,10.1177/1745691612462588,"https://etiennelebel.com/documents/osc(2012,pps).pdf",,,345,,,,,,"December 20, 2018",,,,,,,,conceptual,,,,,"[Replicability] is a defining feature of science. However, because of strong incentives for innovation and weak incentives for confirmation, direct replication is rarely practiced or published. The [Replicability] Project is an open, large-scale, collaborative effort to systematically examine the rate and predictors of [replicability] in psychological science. So far, 72 volunteer researchers from 41 institutions have organized to openly and transparently replicate studies published in three prominent psychological journals in 2008. Multiple methods will be used to evaluate the findings, calculate an empirical rate of replication, and investigate factors that predict [replicability]. Whatever the result, a better understanding of [replicability] will ultimately improve confidence in scientific methodology and findings.",methodology; replication; reproducibility; psychological science; open,,None to declare.,None to declare.,,,
SV Paunonen & EP LeBel,2012,Socially desirable responding and its elusive effects on the validity of personality assessments,Journal of Personality and Social Psychology,10.1037/a0028165,"https://etiennelebel.com/documents/p&l(2012,jpsp).pdf",,,80,,,,,,"December 20, 2018",,,,,https://osf.io/g8k8g/files/,,,conceptual,,,,,"Past studies of socially desirable self-reports on the items of personality measures have found inconsistent effects of the response bias on the measures’ predictive validities, with some studies reporting small effects and other studies reporting large effects. Using Monte Carlo methods, we evaluated various models of socially desirable responding by systematically adding predetermined amounts of the bias to the simulated personality trait scores of hypothetical test respondents before computing test–criterion validity correlations. Our study generally supported previous findings that have reported relatively minor decrements in criterion prediction, even with personality scores that were massively infused with desirability bias. Furthermore, the response bias failed to reveal itself as a statistical moderator of test validity or as a suppressor of validity. Large differences between some respondents’ obtained test scores and their true trait scores, however, meant that the personality measure’s construct validity would be severely compromised and, more specifically, that estimates of those individuals’ criterion performance would be grossly in error. Our discussion focuses on reasons for the discrepant results reported in the literature pertaining to the effect of socially desirable responding on criterion validity. More important, we explain why the lack of effects of desirability bias on the usual indicators of validity, moderation, and suppression should not be surprising.",social desirability; personality assessment; response bias; test validity; Monte Carlo simulation,,None to declare.,"Social Science and Humanities Research Council (Canada, SSHRC grant # 410-2010-2586: SV Paunonen), SSHRC (Canada, SSHRC doctoral fellowship # 767-2007-1425: EP LeBel)",L King,"Anonymous reviewer 1, Anonymous reviewer 2",
EP LeBel & KR Peters,2011,Fearing the future of empirical psychology: Bem's (2011) evidence of psi as a case study of deficiencies in modal research practice,Review of General Psychology,10.1037/a0025172,"https://etiennelebel.com/documents/l&p(2011,pspb).pdf",,,140,,,,,,"December 20, 2018",,,,,,,,conceptual,,,,,"In this methodological commentary, we use Bem’s (2011) recent article reporting experimental evidence for psi as a case study for discussing important deficiencies in modal research practice in empirical psychology. We focus on (a) overemphasis on conceptual rather than close replication, (b) insufficient attention to verifying the soundness of measurement and experimental procedures, and (c) flawed implementation of null hypothesis significance testing. We argue that these deficiencies contribute to weak method-relevant beliefs that, in conjunction with overly strong theory-relevant beliefs, lead to a systemic and pernicious bias in the interpretation of data that favors a researcher’s theory. Ultimately, this interpretation bias increases the risk of drawing incorrect conclusions about human psychology. Our analysis points to concrete recommendations for improving research practice in empirical psychology. We recommend (a) a stronger emphasis on close replication, (b) routinely verifying the integrity of measurement instruments and experimental procedures, and (c) using stronger, more diagnostic forms of null hypothesis testing.",psi; close replication; NHST; file drawer problem; modal research practice,,None to declare.,"Social Science and Humanities Research Council (Canada, SSHRC doctoral fellowship # 767-2007-1425: EP LeBel)",D Candland,Anonymous reviewer 1,
EP LeBel & SV Paunonen,2011,Sexy but often unreliable: Impact of unreliability on the replicability of experimental findings involving implicit measures,Personality and Social Psychology Bulletin,10.1177/0146167211400619,"https://etiennelebel.com/documents/l&p(2011,pspb).pdf",,,95,,,,,,"December 20, 2018",,,,,http://figshare.com/articles/SPSS_syntax_for_LeBel_Paunonen_2011_PSPB_/953179,,,conceptual,,,,,"Implicit measures have contributed to important insights in almost every area of psychology. However, various issues and challenges remain concerning their use, one of which is their considerable variation in reliability, with many implicit measures having questionable reliability. The goal of the present investigation was to examine an overlooked consequence of this liability with respect to replication, when such implicit measures are used as dependent variables in experimental studies. Using a Monte Carlo simulation, the authors demonstrate that a higher level of unreliability in such dependent variables is associated with substantially lower levels of replicability. The results imply that this overlooked consequence can have farreaching repercussions for the development of a cumulative science. The authors recommend the routine assessment and reporting of the reliability of implicit measures and also urge the improvement of implicit measures with low reliability.",implicit measures; replicability; replication; reliability; measurement error ,,None to declare.,"Social Science and Humanities Research Council (Canada, SSHRC doctoral fellowship # 767-2007-1425: EP LeBel), SSHRC grant (Canada, grant # 410-2010-2586: SV Paunonen)",DA Stapel,"Anonymous reviewer 1, Anonymous reviewer 2",
EP LeBel,2010,Attitude accessibility as a moderator of implicit and explicit self-esteem correspondence,Self and Identity,10.1080/15298860902979166,https://etiennelebel.com/documents/l2010sai.pdf,,,18,,,,,,"December 20, 2018",,,http://figshare.com/articles/LeBel_2010_S_I_Data_and_syntax_/953183,http://figshare.com/articles/LeBel_2010_S_I_Data_and_syntax_/953183,http://figshare.com/articles/LeBel_2010_S_I_Data_and_syntax_/953183,basic7,"February 15, 2018",original,,,,,"A key question in the self-esteem literature involves the conditions under which implicit and explicit self-esteem correspond. The current investigation adds to this literature by using a novel strategy capitalizing on natural variation in self-report response latencies to shed further light on the conditions of implicit and explicit selfesteem consistency. The current study demonstrated that implicit and explicit selfesteem corresponded for highly accessible self-attitudes (as indexed by response latencies to the Rosenberg Self-Esteem Scale items, RSES; Rosenberg, 1965) whereas implicit and explicit self-esteem were virtually unrelated for less accessible self-attitudes. This effect was found using both the Name Letter Task (NLT; Nuttin, 1985) and the Self-Esteem Implicit Association Test (SE-IAT; Greenwald & Farnham, 2000) as measures of implicit self-esteem.",explicit self-esteem; implicit–explicit correspondence; implicit self-esteem; Name Letter Task; self-esteem Implicit Association Test,,None to declare.,"Social Science and Humanities Research Council (Canada, SSHRC doctoral fellowship # 767-2007-1425: EP LeBel)",J Bosson,"Anonymous reviewer 1, Anonymous reviewer 2",
EP LeBel & B Gawronski,2009,How to find what's in a name: Scrutinizing the optimality of five scoring algorithms for the name-letter task,European Journal of Personality,10.1002/per.705,"https://etiennelebel.com/documents/l&g(2009,ejp).pdf",,,94,,,,,,"December 20, 2018",,,,http://figshare.com/articles/LeBel_Gawronski_2009_EJP_/953189,http://figshare.com/articles/LeBel_Gawronski_2009_EJP_/953189,,,reanalysis,,,,,"Although the name-letter task (NLT) has become an increasingly popular technique to measure implicit self-esteem (ISE), researchers have relied on different algorithms to compute NLT scores and the psychometric properties of these differently computed scores have never been thoroughly investigated. Based on 18 independent samples, including 2690 participants, the current research examined the optimality of five scoring algorithms based on the following criteria: reliability; variability in reliability estimates across samples; types of systematic error variance controlled for; systematic production of outliers and shape of the distribution of scores. Overall, an ipsatized version of the original algorithm exhibited the most optimal psychometric properties, which is recommended for future research using the NLT.",name-letter task; initial preference task; implicit self-esteem; reliability; validity,,None to declare.,"Social Science and Humanities Research Council (Canada, SSHRC doctoral fellowship # 767-2007-1425: EP LeBel); Canada Research Chairs Program Grant (Canada, grant # 202555: B Gawronski); SSHRC (grant # 410-2008-2247: B Gawronski)",M Perugini,Anonymous reviewer 1,
EP LeBel & L Campbell ,2009,"Implicit partner affect, relationship satisfaction, and the prediction of romantic breakup",Journal of Experimental Social Psychology,10.1016/j.jesp.2009.07.003,"https://etiennelebel.com/documents/l&c(2009,jesp).pdf",,,50,,,,,,"December 20, 2018",,,,,,,,original,,,,,"The current research investigated the role of spontaneous partner feelings (implicit partner affect) in the dynamics of relationship satisfaction, commitment, and romantic dissolution. Participants completed a variant of the name-letter task as a measure of implicit partner affect, and self-report measures of relationship satisfaction and commitment. Approximately 4 months later, participants were contacted to assess their current relationship status. Overall, participants showed a biased preference for their partner’s initials (after adjusting for proper baselines), indicating the presence of positive implicit partner affect. Participants with more positive implicit partner affect were more satisfied with, but not more committed to, their relationship. Additionally, implicit partner affect exerted a significant indirect effect on relationship stability. These effects were independent of relationship length, age, and gender. Implications for the role of automatic affective processes in relationship processes and the utility of indirect measures for shedding light on relationship dynamics are discussed.",implicit partner evaluation; implicit measures; name-letter effect; relationship satisfaction; relationship stability,,None to declare.,"Social Science and Humanities Research Council (Canada, SSHRC doctoral fellowship # 767-2007-1425: EP LeBel), SSHRC grant (Canada: L Campbell)",J Cooper,Anonymous reviewer 1,
B Gawronski & EP LeBel,2008,"Understanding patterns of attitude change: When implicit measures show change, but explicit measures do not",Journal of Experimental Social Psychology,10.1016/j.jesp.2008.04.005,https://etiennelebel.com/documents/gl2008jesp.pdf,,,256,,,,,,"December 20, 2018",,,,,,,,original,,,,,"A common assumption in research on attitudes is that indirect measures assess relatively stable implicit attitudes, whereas traditional self-report measures assess more recently acquired explicit attitudes that coexist with old, presumably stable implicit attitudes. This assumption seems difficult to reconcile with research showing experimentally induced changes on implicit but not explicit measures. The present research tested a process-account of such asymmetrical patterns. Specifically, we argue that implicit measures show experimental effects that do not emerge on explicit measures when (a) the pairing of an attitude object with positive or negative valence creates new automatic associations in memory, and, at the same time, (b) the consideration of additional information about the attitude object eliminates the impact of automatic associations on self-reported evaluative judgments. Results from three studies support these predictions. Implications for research on attitude change are discussed.",attitude change; evaluative conditioning; implicit measures; introspection; mere ownership,,None to declare.,"Canada Research Chairs Program Grant (Canada, grant # 202555: B Gawronski), SSHRC (Canada, grant # 410-2005-1339: B Gawronski), Academic Development Fund (Canada, UWO, grant # 05-303: B Gawronski)",,,
"B Gawronski, EP LeBel, & KR Peters (2007)",2007,What do implicit measures tell us? Scrutinizing the validity of three common assumptions,Perspectives on Psychological Science,10.1111/j.1745-6916.2007.00036.x,https://etiennelebel.com/documents/glp2007pps.pdf,,,296,,,,,,"December 20, 2018",,,,,,,,conceptual,,,,,"Experimental paradigms designed to assess ‘implicit’ representations are currently very popular in many areas of psychology. The present article addresses the validity of three widespread assumptions in research using these paradigms: that (a) implicit measures reflect unconscious or introspectively inaccessible representations; (b) the major difference between implicit measures and self-reports is that implicit measures are resistant or less susceptible to social desirability; and (c) implicit measures reflect highly stable, older representations that have their roots in long-term socialization experiences. Drawing on a review of the available evidence, we conclude that the validity of all three assumptions is equivocal and that theoretical interpretations should be adjusted accordingly. We discuss an alternative conceptualization that distinguishes between activation and validation processes.",,,None to declare.,"Canada Research Chairs Program Grant (Canada, grant # 202555: B Gawronski), SSHRC (Canada, grant # 410-2005-1339: B Gawronski), Academic Development Fund (Canada, UWO, grant # 05-303: B Gawronski)",,,
